




\chapter{ANOVA and Experimental Design }

\section{Designed Experiments}
\begin{itemize}
	\item In observational studies you try to examine and measure things as they naturally occur. In experimental studies you impose some manipulation and measure its effects. It is easier to generalize from
	observational studies, but it is easier to determine causality from experimental studies.
	\item The objects on which an experiment is performed are called the experimental units. Human experimental units used to be called subjects," but we now call them research participants."
	\item The explanatory variables in an experiment are referred to as factors, while the values each factor
	can have are called its levels. A specifoc experimental condition applied to a set of units is called a
	treatment.
	\item The effectiveness of a treatment is generally measured by comparing the results of units that underwent
	the treatment to the results of units in a control condition. Units in a control condition go through the
	experiment but never receive the treatment.
	\item It is generally not a good idea to determine the e®ect of a treatment by comparing the units before
	the treatment to the same units after the treatment. Just being in an experiment can sometimes cause
	changes, even if the treatment itself doesn't really do anything. This is called the placebo effect.
	\item The basic idea of an experiment is that if you control for everything in the environment except for
	the factor that you manipulate, then any differences you observe between different groups in your
	experiment must be caused by the factor. It is therefore very important that the groups of experimental
	units you have in each level of your factor are basically the same. If there is some difference between
	the types of units in your groups, then the results might be caused by those differences instead of your
	treatment.
	\item Sometimes people use matching to make their groups similar. In this case you assign people to the
	different levels of your factor in such a way that for every person in one factor level you have a similar
	person in each of the other levels.
	\item The preferred way to make your groups similar is by randomization. In this case you just randomly
	pick people to be in each of your groups, relying on the fact that on average the differences between
	the groups will average out. Not only does this require less effort, but you don't have to know ahead
	of time what are the important things that you need to match on.
	\item There are many different ways to randomly assign your experimental units to conditions. You can use
	a table of random numbers, a mathematical calculator that produces random digits, or you can use
	statistical software.
	\item Randomization is one of the basic ideas behind statistics. When we randomly assign units to be in
	either the treatment or control conditions, there will be some differences between the groups. However,
	this is not a problem because mathematicians know a lot about how random variables work. When we
	see a difference between the groups we can figure out the probability that the difference is just due to
	the way that we assigned the units to the groups. If the probability is too low for us to believe that the
	results were just due to chance we say that the difference is statistically significant, and we conclude
	that our treatment had an effect.
	\item In conclusion, when designing an experiment you want to:
	\begin{enumerate}
		\item Control the effects of irrelevant variables.
		\item Randomize the assignment of experimental units to treatment conditions
		\item Replicate your experiment across a number of experimental units.
	\end{enumerate}
\end{itemize}




\subsection{ $2^2$ Design}

The simplest type of $2^k$ design is the $2^2$, i.e. two factors, A nd B, each with two levels. We usually think of these levels as the low and high levels of the factor.


\section{Analysis of Two-factor Designs}

A two-factor analysis of variance consists of three significance tests: a test of each of the two main effects and a test of the interaction of the variables. An analysis of variance summary table is a convenient way to display the results of the significance tests. A summary table for the hypothetical experiment described in the section on factorial designs and a graph of the means for the experiment are shown below.

\begin{verbatim}
Sum of        Mean
SOURCE   df      Squares      Square      F       p
T    1    47125.3333  47125.3333  384.174   0.000
D    2       42.6667     21.3333    0.174   0.841
TD    2     1418.6667    709.3333    5.783   0.006
ERROR   42     5152.0000    122.6667
TOTAL   47    53738.6667
\end{verbatim}

\subsection{Sources of Variation}

The summary table shows four sources of variation: (1) Task, (2) Drug dosage, (3) the Task x Drug dosage interaction, and (4) Error.

\subsection{Degrees of Freedom}

\begin{itemize}
	\item The degrees of freedom total is always equal to the total number of numbers in the analysis minus one. The experiment on task and drug dosage had eight subjects in each of the six groups resulting in a total of 48 subjects. Therefore, df total = 48 - 1 = 47.
	
	\item The degrees of freedom for the main effect of a factor is always equal to the number of levels of the factor minus one. Therefore, df task = 2 - 1 = 1 since there were two levels of task (simple and complex). Similarly, df dosage = 3 - 1 = 2 since there were three levels of drug dosage (0 mg, 100 mg, and 200 mg).
	
	\item The degrees of freedom for an interaction is equal to the product of the degrees of freedom of the variables in the interaction. Thus, the degrees of freedom for the Task x Dosage interaction is the product of the degrees of freedom for task (1) and the degrees of freedom for dosage (2). Therefore, df Task x Dosage = 1 x 2 = 2.
	
	\item The degrees of freedom error is equal to the degrees of freedom total minus the degrees of freedom for all the effects. Therefore, df error = 47 - 1 - 2 - 2 = 42.
\end{itemize}

\subsection{Mean Squares}
As in the case of a one-factor design, each mean square is equal to the sum of squares divided by the degrees of freedom. For instance, Mean square dosage = 42.6667/2 = 21.333 where the sum of squares dosage is 42.6667 and the degrees of freedom dosage is 2.


\subsection{F Ratios}
The F ratio for an effect is computed by dividing the mean square for the effect by the mean square error. For example, the F ratio for the Task x Dosage interaction is computed by dividing the mean square for the interaction ( 709.3333) by the mean square error (122.6667). The resulting F ratio is: F = 709.3333/122.6667 = 5.783


\subsection{Probability Values}
To compute a probability value for an F ratio, you must know the degrees of freedom for the F ratio. The degrees of freedom numerator is equal to the degrees of freedom for the effect. The degrees of freedom denominator is equal to the degrees of freedom error. Therefore, the degrees of freedom for the F ratio for the main effect of task are 1 and 42, the degrees of freedom for the F ratio for the main effect of drug dosage are 2 and 42, and the degrees of freedom for the F for the Task x Dosage interaction are 2 and 42.

An F distribution calculator can be used to find the probability values. For the interaction, the probability value associated with an F of 5.783 with 2 and 42 df is 0.006.

\subsection{Drawing Conclusions}

When a main effect is significant, the null hypothesis that there is no main effect in the population can be rejected. In this example, the effect of task was significant. Therefore it can be concluded that, in the population, the mean time to complete the complex task is greater than the mean time to complete the simple task (hardly surprising). The effect of dosage was not significant. Therefore, there is no convincing evidence that the mean time to complete a task (in the population) is different for the three dosage levels

The significant Task x Dosage interaction indicates that the effect of dosage (in the population) differs depending on the level of task. Specifically, increasing the dosage slows down performance on the complex task and speeds up performance on the simple task. The effect of increasing the dosage therefore depends on whether the task is complex of simple.

There will always be some interaction in the sample data. The significance test of the interaction lets you know whether you can infer that there is an interaction in the population.


\chapter{ANOVA and Experimental Design }

\section{Designed Experiments}
\begin{itemize}
	\item In observational studies you try to examine and measure things as they naturally occur. In experimental studies you impose some manipulation and measure its effects. It is easier to generalize from
	observational studies, but it is easier to determine causality from experimental studies.
	\item The objects on which an experiment is performed are called the experimental units. Human experimental units used to be called subjects," but we now call them research participants."
	\item The explanatory variables in an experiment are referred to as factors, while the values each factor
	can have are called its levels. A specifoc experimental condition applied to a set of units is called a
	treatment.
	\item The effectiveness of a treatment is generally measured by comparing the results of units that underwent
	the treatment to the results of units in a control condition. Units in a control condition go through the
	experiment but never receive the treatment.
	\item It is generally not a good idea to determine the e®ect of a treatment by comparing the units before
	the treatment to the same units after the treatment. Just being in an experiment can sometimes cause
	changes, even if the treatment itself doesn't really do anything. This is called the placebo effect.
	\item The basic idea of an experiment is that if you control for everything in the environment except for
	the factor that you manipulate, then any differences you observe between different groups in your
	experiment must be caused by the factor. It is therefore very important that the groups of experimental
	units you have in each level of your factor are basically the same. If there is some difference between
	the types of units in your groups, then the results might be caused by those differences instead of your
	treatment.
	\item Sometimes people use matching to make their groups similar. In this case you assign people to the
	different levels of your factor in such a way that for every person in one factor level you have a similar
	person in each of the other levels.
	\item The preferred way to make your groups similar is by randomization. In this case you just randomly
	pick people to be in each of your groups, relying on the fact that on average the differences between
	the groups will average out. Not only does this require less effort, but you don't have to know ahead
	of time what are the important things that you need to match on.
	\item There are many different ways to randomly assign your experimental units to conditions. You can use
	a table of random numbers, a mathematical calculator that produces random digits, or you can use
	statistical software.
	\item Randomization is one of the basic ideas behind statistics. When we randomly assign units to be in
	either the treatment or control conditions, there will be some differences between the groups. However,
	this is not a problem because mathematicians know a lot about how random variables work. When we
	see a difference between the groups we can figure out the probability that the difference is just due to
	the way that we assigned the units to the groups. If the probability is too low for us to believe that the
	results were just due to chance we say that the difference is statistically significant, and we conclude
	that our treatment had an effect.
	\item In conclusion, when designing an experiment you want to:
	\begin{enumerate}
		\item Control the effects of irrelevant variables.
		\item Randomize the assignment of experimental units to treatment conditions
		\item Replicate your experiment across a number of experimental units.
	\end{enumerate}
\end{itemize}




\subsection{ $2^2$ Design}

The simplest type of $2^k$ design is the $2^2$, i.e. two factors, A nd B, each with two levels. We usually think of these levels as the low and high levels of the factor.


\section{Analysis of Two-factor Designs}

A two-factor analysis of variance consists of three significance tests: a test of each of the two main effects and a test of the interaction of the variables. An analysis of variance summary table is a convenient way to display the results of the significance tests. A summary table for the hypothetical experiment described in the section on factorial designs and a graph of the means for the experiment are shown below.

\begin{verbatim}
Sum of        Mean
SOURCE   df      Squares      Square      F       p
T    1    47125.3333  47125.3333  384.174   0.000
D    2       42.6667     21.3333    0.174   0.841
TD    2     1418.6667    709.3333    5.783   0.006
ERROR   42     5152.0000    122.6667
TOTAL   47    53738.6667
\end{verbatim}

\subsection{Sources of Variation}

The summary table shows four sources of variation: (1) Task, (2) Drug dosage, (3) the Task x Drug dosage interaction, and (4) Error.

\subsection{Degrees of Freedom}

\begin{itemize}
	\item The degrees of freedom total is always equal to the total number of numbers in the analysis minus one. The experiment on task and drug dosage had eight subjects in each of the six groups resulting in a total of 48 subjects. Therefore, df total = 48 - 1 = 47.
	
	\item The degrees of freedom for the main effect of a factor is always equal to the number of levels of the factor minus one. Therefore, df task = 2 - 1 = 1 since there were two levels of task (simple and complex). Similarly, df dosage = 3 - 1 = 2 since there were three levels of drug dosage (0 mg, 100 mg, and 200 mg).
	
	\item The degrees of freedom for an interaction is equal to the product of the degrees of freedom of the variables in the interaction. Thus, the degrees of freedom for the Task x Dosage interaction is the product of the degrees of freedom for task (1) and the degrees of freedom for dosage (2). Therefore, df Task x Dosage = 1 x 2 = 2.
	
	\item The degrees of freedom error is equal to the degrees of freedom total minus the degrees of freedom for all the effects. Therefore, df error = 47 - 1 - 2 - 2 = 42.
\end{itemize}

\subsection{Mean Squares}
As in the case of a one-factor design, each mean square is equal to the sum of squares divided by the degrees of freedom. For instance, Mean square dosage = 42.6667/2 = 21.333 where the sum of squares dosage is 42.6667 and the degrees of freedom dosage is 2.


\subsection{F Ratios}
The F ratio for an effect is computed by dividing the mean square for the effect by the mean square error. For example, the F ratio for the Task x Dosage interaction is computed by dividing the mean square for the interaction ( 709.3333) by the mean square error (122.6667). The resulting F ratio is: F = 709.3333/122.6667 = 5.783


\subsection{Probability Values}
To compute a probability value for an F ratio, you must know the degrees of freedom for the F ratio. The degrees of freedom numerator is equal to the degrees of freedom for the effect. The degrees of freedom denominator is equal to the degrees of freedom error. Therefore, the degrees of freedom for the F ratio for the main effect of task are 1 and 42, the degrees of freedom for the F ratio for the main effect of drug dosage are 2 and 42, and the degrees of freedom for the F for the Task x Dosage interaction are 2 and 42.

An F distribution calculator can be used to find the probability values. For the interaction, the probability value associated with an F of 5.783 with 2 and 42 df is 0.006.

\subsection{Drawing Conclusions}

When a main effect is significant, the null hypothesis that there is no main effect in the population can be rejected. In this example, the effect of task was significant. Therefore it can be concluded that, in the population, the mean time to complete the complex task is greater than the mean time to complete the simple task (hardly surprising). The effect of dosage was not significant. Therefore, there is no convincing evidence that the mean time to complete a task (in the population) is different for the three dosage levels

The significant Task x Dosage interaction indicates that the effect of dosage (in the population) differs depending on the level of task. Specifically, increasing the dosage slows down performance on the complex task and speeds up performance on the simple task. The effect of increasing the dosage therefore depends on whether the task is complex of simple.

There will always be some interaction in the sample data. The significance test of the interaction lets you know whether you can infer that there is an interaction in the population.

